{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5436020b",
   "metadata": {},
   "source": [
    "# Defining Custom Tools\n",
    "\n",
    "When constructing your own agent, you will need to provide it with a list of Tools that it can use. Besides the actual function that is called, the Tool consists of several components:\n",
    "\n",
    "- `name` (str), is required and must be unique within a set of tools provided to an agent\n",
    "- `description` (str), is optional but recommended, as it is used by an agent to determine tool use\n",
    "- `return_direct` (bool), defaults to False\n",
    "- `args_schema` (Pydantic BaseModel), is optional but recommended, can be used to provide more information (e.g., few-shot examples) or validation for expected parameters.\n",
    "\n",
    "\n",
    "There are two main ways to define a tool, we will cover both in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aaba18c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "from langchain.utilities import SerpAPIWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c3874",
   "metadata": {},
   "source": [
    "Initialize the LLM to use for the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ed392e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8bc72c2",
   "metadata": {},
   "source": [
    "## Completely New Tools - String Input and Output\n",
    "\n",
    "The simplest tools accept a single query string and return a string output. If your tool function requires multiple arguments, you might want to skip down to the `StructuredTool` section below.\n",
    "\n",
    "There are two ways to do this: either by using the Tool dataclass, or by subclassing the BaseTool class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b63fcc3b",
   "metadata": {},
   "source": [
    "### Tool dataclass\n",
    "\n",
    "The 'Tool' dataclass wraps functions that accept a single string input and returns a string output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ff7670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the tool configs that are needed.\n",
    "search = SerpAPIWrapper()\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=search.run,\n",
    "        name=\"Search\",\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "        # coroutine= ... <- you can specify an async method if desired as well\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9b560f7",
   "metadata": {},
   "source": [
    "You can also define a custom `args_schema` to provide more information about inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "631361e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    question: str = Field()\n",
    "\n",
    "\n",
    "tools.append(\n",
    "    Tool.from_function(\n",
    "        func=llm_math_chain.run,\n",
    "        name=\"Calculator\",\n",
    "        description=\"useful for when you need to answer questions about math\",\n",
    "        args_schema=CalculatorInput,\n",
    "        # coroutine= ... <- you can specify an async method if desired as well\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b93047d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f96a891",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out who Leo DiCaprio's girlfriend is and then calculate her current age raised to the 0.43 power.\n",
      "Action: Search\n",
      "Action Input: \"Leo DiCaprio's girlfriend\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLeonardo DiCaprio may have found The One in Vittoria Ceretti. “They are in love,” a source exclusively reveals in the latest issue of Us Weekly. “Leo was clearly very proud to be showing Vittoria off and letting everyone see how happy they are together.”\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found out that Leo DiCaprio's girlfriend is Vittoria Ceretti. Now I need to calculate her current age raised to the 0.43 power.\n",
      "Action: Calculator\n",
      "Action Input: Vittoria Ceretti's current age\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "Vittoria Ceretti's current age\u001b[32;1m\u001b[1;3m```text\n",
      "2022 - 1998\n",
      "```\n",
      "...numexpr.evaluate(\"2022 - 1998\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m24\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 24\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know that Vittoria Ceretti's current age is 24. Now I can calculate her current age raised to the 0.43 power.\n",
      "Action: Calculator\n",
      "Action Input: 24^0.43\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "24^0.43\u001b[32;1m\u001b[1;3m```text\n",
      "24**0.43\n",
      "```\n",
      "...numexpr.evaluate(\"24**0.43\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m3.9218486893172186\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 3.9218486893172186\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know that Vittoria Ceretti's current age raised to the 0.43 power is approximately 3.92.\n",
      "Final Answer: Vittoria Ceretti's current age raised to the 0.43 power is approximately 3.92.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Vittoria Ceretti's current age raised to the 0.43 power is approximately 3.92.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f12eaf0",
   "metadata": {},
   "source": [
    "### Subclassing the BaseTool\n",
    "\n",
    "You can also directly subclass `BaseTool`. This is useful if you want more control over the instance variables or if you want to propagate callbacks to nested chains or other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c58a7c40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "\n",
    "\n",
    "class CustomSearchTool(BaseTool):\n",
    "    name = \"custom_search\"\n",
    "    description = \"useful for when you need to answer questions about current events\"\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        return search.run(query)\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")\n",
    "\n",
    "\n",
    "class CustomCalculatorTool(BaseTool):\n",
    "    name = \"Calculator\"\n",
    "    description = \"useful for when you need to answer questions about math\"\n",
    "    args_schema: Type[BaseModel] = CalculatorInput\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        return llm_math_chain.run(query)\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"Calculator does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3318a46f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [CustomSearchTool(), CustomCalculatorTool()]\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a2cebbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out who Leo DiCaprio's girlfriend is and then calculate her current age raised to the 0.43 power.\n",
      "Action: custom_search\n",
      "Action Input: \"Leo DiCaprio's girlfriend\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLeonardo DiCaprio may have found The One in Vittoria Ceretti. “They are in love,” a source exclusively reveals in the latest issue of Us Weekly. “Leo was clearly very proud to be showing Vittoria off and letting everyone see how happy they are together.”\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found out that Leo DiCaprio's girlfriend is Vittoria Ceretti. Now I need to calculate her current age raised to the 0.43 power.\n",
      "Action: Calculator\n",
      "Action Input: Vittoria Ceretti's current age\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "Vittoria Ceretti's current age\u001b[32;1m\u001b[1;3m```text\n",
      "2022 - 1998\n",
      "```\n",
      "...numexpr.evaluate(\"2022 - 1998\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m24\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 24\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know that Vittoria Ceretti's current age is 24. Now I can calculate her current age raised to the 0.43 power.\n",
      "Action: Calculator\n",
      "Action Input: 24^0.43\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "24^0.43\u001b[32;1m\u001b[1;3m```text\n",
      "24**0.43\n",
      "```\n",
      "...numexpr.evaluate(\"24**0.43\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m3.9218486893172186\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 3.9218486893172186\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer. Vittoria Ceretti's current age raised to the 0.43 power is approximately 3.92.\n",
      "Final Answer: 3.92\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.92'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824eaf74",
   "metadata": {},
   "source": [
    "### Using the decorator\n",
    "\n",
    "To make it easier to define custom tools, a `@tool` decorator is provided. This decorator can be used to quickly create a `Tool` from a simple function. The decorator uses the function name as the tool name by default, but this can be overridden by passing a string as the first argument. Additionally, the decorator will use the function's docstring as the tool's description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f15307d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='search_api', description='search_api(query: str) -> str - Searches the API for the query.', args_schema=<class 'pydantic.main.search_apiSchemaSchema'>, func=<function search_api at 0x1252d7ac0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_api(query: str) -> str:\n",
    "    \"\"\"Searches the API for the query.\"\"\"\n",
    "    return f\"Results for query {query}\"\n",
    "\n",
    "\n",
    "search_api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ee8c1",
   "metadata": {},
   "source": [
    "You can also provide arguments like the tool name and whether to return directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28cdf04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool(\"search\", return_direct=True)\n",
    "def search_api(query: str) -> str:\n",
    "    \"\"\"Searches the API for the query.\"\"\"\n",
    "    return \"Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1085a4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='search', description='search(query: str) -> str - Searches the API for the query.', args_schema=<class 'pydantic.main.searchSchemaSchema'>, return_direct=True, func=<function search_api at 0x1252d7760>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de34a6a3",
   "metadata": {},
   "source": [
    "You can also provide `args_schema` to provide more information about the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3a5c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")\n",
    "\n",
    "\n",
    "@tool(\"search\", return_direct=True, args_schema=SearchInput)\n",
    "def search_api(query: str) -> str:\n",
    "    \"\"\"Searches the API for the query.\"\"\"\n",
    "    return \"Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7914ba6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='search', description='search(query: str) -> str - Searches the API for the query.', args_schema=<class '__main__.SearchInput'>, return_direct=True, func=<function search_api at 0x1252d76d0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_api"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61d2e80b",
   "metadata": {},
   "source": [
    "## Custom Structured Tools\n",
    "\n",
    "If your functions require more structured arguments, you can use the `StructuredTool` class directly, or still subclass the `BaseTool` class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5be41722",
   "metadata": {},
   "source": [
    "### StructuredTool dataclass\n",
    "\n",
    "To dynamically generate a structured tool from a given function, the fastest way to get started is with `StructuredTool.from_function()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c070216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "\n",
    "def post_message(url: str, body: dict, parameters: Optional[dict] = None) -> str:\n",
    "    \"\"\"Sends a POST request to the given url with the given body and parameters.\"\"\"\n",
    "    result = requests.post(url, json=body, params=parameters)\n",
    "    return f\"Status: {result.status_code} - {result.text}\"\n",
    "\n",
    "\n",
    "tool = StructuredTool.from_function(post_message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb0a38eb",
   "metadata": {},
   "source": [
    "### Subclassing the BaseTool\n",
    "\n",
    "The BaseTool automatically infers the schema from the `_run` method's signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7505c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "\n",
    "\n",
    "class CustomSearchTool(BaseTool):\n",
    "    name = \"custom_search\"\n",
    "    description = \"useful for when you need to answer questions about current events\"\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        query: str,\n",
    "        engine: str = \"google\",\n",
    "        gl: str = \"us\",\n",
    "        hl: str = \"en\",\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        search_wrapper = SerpAPIWrapper(params={\"engine\": engine, \"gl\": gl, \"hl\": hl})\n",
    "        return search_wrapper.run(query)\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        query: str,\n",
    "        engine: str = \"google\",\n",
    "        gl: str = \"us\",\n",
    "        hl: str = \"en\",\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")\n",
    "\n",
    "\n",
    "# You can provide a custom args schema to add descriptions or custom validation\n",
    "\n",
    "\n",
    "class SearchSchema(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")\n",
    "    engine: str = Field(description=\"should be a search engine\")\n",
    "    gl: str = Field(description=\"should be a country code\")\n",
    "    hl: str = Field(description=\"should be a language code\")\n",
    "\n",
    "\n",
    "class CustomSearchTool(BaseTool):\n",
    "    name = \"custom_search\"\n",
    "    description = \"useful for when you need to answer questions about current events\"\n",
    "    args_schema: Type[SearchSchema] = SearchSchema\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        query: str,\n",
    "        engine: str = \"google\",\n",
    "        gl: str = \"us\",\n",
    "        hl: str = \"en\",\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        search_wrapper = SerpAPIWrapper(params={\"engine\": engine, \"gl\": gl, \"hl\": hl})\n",
    "        return search_wrapper.run(query)\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        query: str,\n",
    "        engine: str = \"google\",\n",
    "        gl: str = \"us\",\n",
    "        hl: str = \"en\",\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d68b0ac",
   "metadata": {},
   "source": [
    "### Using the decorator\n",
    "\n",
    "The `tool` decorator creates a structured tool automatically if the signature has multiple arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38d11416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def post_message(url: str, body: dict, parameters: Optional[dict] = None) -> str:\n",
    "    \"\"\"Sends a POST request to the given url with the given body and parameters.\"\"\"\n",
    "    result = requests.post(url, json=body, params=parameters)\n",
    "    return f\"Status: {result.status_code} - {result.text}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d0430d6",
   "metadata": {},
   "source": [
    "## Modify existing tools\n",
    "\n",
    "Now, we show how to load existing tools and modify them directly. In the example below, we do something really simple and change the Search tool to have the name `Google Search`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79213f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1067dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c66ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools[0].name = \"Google Search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f45b5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "565e2b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who Leo DiCaprio's girlfriend is and then calculate her age raised to the 0.43 power.\n",
      "Action: Google Search\n",
      "Action Input: \"Leo DiCaprio girlfriend\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mCeretti has been modeling since she was 14-years-old and is well known on the runway.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out her age.\n",
      "Action: Google Search\n",
      "Action Input: \"Camila Morrone age\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m26 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate her age raised to the 0.43 power.\n",
      "Action: Calculator\n",
      "Action Input: 26^0.43\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 4.059182145592686\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Camila Morrone is Leo DiCaprio's girlfriend and her current age raised to the 0.43 power is 4.059182145592686.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Camila Morrone is Leo DiCaprio's girlfriend and her current age raised to the 0.43 power is 4.059182145592686.\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376813ed",
   "metadata": {},
   "source": [
    "## Defining the priorities among Tools\n",
    "When you made a Custom tool, you may want the Agent to use the custom tool more than normal tools.\n",
    "\n",
    "For example, you made a custom tool, which gets information on music from your database. When a user wants information on songs, You want the Agent to use  `the custom tool` more than the normal `Search tool`. But the Agent might prioritize a normal Search tool.\n",
    "\n",
    "This can be accomplished by adding a statement such as `Use this more than the normal search if the question is about Music, like 'who is the singer of yesterday?' or 'what is the most popular song in 2022?'` to the description.\n",
    "\n",
    "An example is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3450512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.agents import AgentType, Tool, initialize_agent\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Music Search\",\n",
    "        func=lambda x: \"'All I Want For Christmas Is You' by Mariah Carey.\",  # Mock Function\n",
    "        description=\"A Music search engine. Use this more than the normal search if the question is about Music, like 'who is the singer of yesterday?' or 'what is the most popular song in 2022?'\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    OpenAI(temperature=0),\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b9a7849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a music search engine to find the answer\n",
      "Action: Music Search\n",
      "Action Input: most famous song of christmas\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m'All I Want For Christmas Is You' by Mariah Carey.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 'All I Want For Christmas Is You' by Mariah Carey.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'All I Want For Christmas Is You' by Mariah Carey.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"what is the most famous song of christmas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc477d43",
   "metadata": {},
   "source": [
    "## Using tools to return directly\n",
    "Often, it can be desirable to have a tool output returned directly to the user, if it’s called. You can do this easily with LangChain by setting the `return_direct` flag for a tool to be True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bb6185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_math_chain = LLMMathChain.from_llm(llm=llm)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about math\",\n",
    "        return_direct=True,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "113ddb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "582439a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to calculate this\n",
      "Action: Calculator\n",
      "Action Input: 2**.12\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 1.086734862526058\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: 1.086734862526058'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"whats 2**.12\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1da459d",
   "metadata": {},
   "source": [
    "## Handling Tool Errors \n",
    "When a tool encounters an error and the exception is not caught, the agent will stop executing. If you want the agent to continue execution, you can raise a `ToolException` and set `handle_tool_error` accordingly. \n",
    "\n",
    "When `ToolException` is thrown, the agent will not stop working, but will handle the exception according to the `handle_tool_error` variable of the tool, and the processing result will be returned to the agent as observation, and printed in red.\n",
    "\n",
    "You can set `handle_tool_error` to `True`, set it a unified string value, or set it as a function. If it's set as a function, the function should take a `ToolException` as a parameter and return a `str` value.\n",
    "\n",
    "Please note that only raising a `ToolException` won't be effective. You need to first set the `handle_tool_error` of the tool because its default value is `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad16fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import Tool\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain_core.tools import ToolException\n",
    "\n",
    "\n",
    "def _handle_error(error: ToolException) -> str:\n",
    "    return (\n",
    "        \"The following errors occurred during tool execution:\"\n",
    "        + error.args[0]\n",
    "        + \"Please try another tool.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def search_tool1(s: str):\n",
    "    raise ToolException(\"The search tool1 is not available.\")\n",
    "\n",
    "\n",
    "def search_tool2(s: str):\n",
    "    raise ToolException(\"The search tool2 is not available.\")\n",
    "\n",
    "\n",
    "search_tool3 = SerpAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c05aa75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"useful for when you need to answer questions about current events.You should give priority to using it.\"\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=search_tool1,\n",
    "        name=\"Search_tool1\",\n",
    "        description=description,\n",
    "        handle_tool_error=True,\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=search_tool2,\n",
    "        name=\"Search_tool2\",\n",
    "        description=description,\n",
    "        handle_tool_error=_handle_error,\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=search_tool3.run,\n",
    "        name=\"Search_tool3\",\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    ChatOpenAI(temperature=0),\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cff8b4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use Search_tool1 or Search_tool2 to find the most recent information about Leo DiCaprio's girlfriend.\n",
      "Action: Search_tool1\n",
      "Action Input: \"Leo DiCaprio girlfriend\"\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe search tool1 is not available.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try using Search_tool2 instead.\n",
      "Action: Search_tool2\n",
      "Action Input: \"Leo DiCaprio girlfriend\"\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe following errors occurred during tool execution:The search tool2 is not available.Please try another tool.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try using Search_tool3 instead.\n",
      "Action: Search_tool3\n",
      "Action Input: \"Leo DiCaprio girlfriend\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mCeretti has been modeling since she was 14-years-old and is well known on the runway.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The information about Leo DiCaprio's girlfriend is not available.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The information about Leo DiCaprio's girlfriend is not available.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Who is Leo DiCaprio's girlfriend?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e90c8aa204a57276aa905271aff2d11799d0acb3547adabc5892e639a5e45e34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
